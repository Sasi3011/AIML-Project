{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce94c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 1. Import Libraries\n",
    "# ========================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.1)\n",
    "\n",
    "\n",
    "# Paths\n",
    "RAW = Path('data/raw')\n",
    "PROC = Path('data/processed')\n",
    "PROC.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582cc4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 2. Load Raw Dataset\n",
    "# ========================\n",
    "\n",
    "# Path to the raw data (note the '..' since the notebook is inside /notebooks)\n",
    "from pathlib import Path\n",
    "\n",
    "RAW = Path('../data/raw')\n",
    "file_path = RAW / 'Smart_Fertilizer_Recommender_Dataset.xlsx'\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_excel(file_path)\n",
    "print('✅ Initial Shape:', df.shape)\n",
    "\n",
    "# Preview first few rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d45471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 3. Handle Missing Values & Data Cleaning\n",
    "# ========================\n",
    "\n",
    "\n",
    "# Check missing values\n",
    "print('Missing Values per Column:')\n",
    "print(df.isnull().sum())\n",
    "\n",
    "\n",
    "# Fill missing numeric values with median\n",
    "num_cols = df.select_dtypes(include=np.number).columns\n",
    "df[num_cols] = df[num_cols].fillna(df[num_cols].median())\n",
    "\n",
    "\n",
    "# Fill categorical with mode\n",
    "cat_cols = df.select_dtypes(exclude=np.number).columns\n",
    "df[cat_cols] = df[cat_cols].apply(lambda x: x.fillna(x.mode()[0]))\n",
    "\n",
    "\n",
    "# Check again\n",
    "print('After Cleaning:')\n",
    "print(df.isnull().sum().sum(), 'missing values remain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d087b896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 4. Feature Engineering\n",
    "# ========================\n",
    "\n",
    "def feature_engineering(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Derived ratios and indices\n",
    "    df['NPK_Ratio'] = df['Nitrogen_Level'] / (df['Phosphorus_Level'] + df['Potassium_Level'] + 1e-6)\n",
    "    df['Fertility_Index'] = (df['Organic_Carbon'] + (df['Moisture_Content'] / 100)) / 2\n",
    "    df['Temperature_Rainfall_Index'] = df['Temperature_C'] / (df['Rainfall_mm'] + 1)\n",
    "    \n",
    "    # pH categorization\n",
    "    df['pH_Category'] = pd.cut(\n",
    "        df['Soil_pH'],\n",
    "        bins=[0, 5.5, 6.5, 7.5, 14],\n",
    "        labels=['Acidic', 'Slightly_Acidic', 'Neutral', 'Alkaline']\n",
    "    )\n",
    "    \n",
    "    # Simplify fertilizer categories if needed\n",
    "    df['Fertilizer_Type'] = df['Fertilizer_Type'].replace({\n",
    "        'Complex': 'Mixed',\n",
    "        'MOP': 'Potash'\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Apply feature engineering\n",
    "df = feature_engineering(df)\n",
    "print('✅ Feature Engineering Complete. Columns:', len(df.columns))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa52b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 5. Encoding Categorical Variables\n",
    "# ========================\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "categorical_cols = ['Crop_Type', 'Region', 'Soil_Type', 'pH_Category', 'Application_Timing']\n",
    "label_encoders = {}\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].astype(str))  # ensure dtype safety\n",
    "    label_encoders[col] = le\n",
    "\n",
    "print('✅ Categorical Encoding Complete.')\n",
    "df[categorical_cols].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1349754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 6. Feature Scaling\n",
    "# ========================\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "num_cols = df.select_dtypes(include=np.number).columns.drop(['Recommended_Quantity_kg_per_acre'])\n",
    "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "print('Feature Scaling Complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce33f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 7. Split Train/Validation/Test Sets\n",
    "# ========================\n",
    "\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.15, random_state=42)\n",
    "train, val = train_test_split(train, test_size=0.15, random_state=42)\n",
    "\n",
    "\n",
    "train.to_csv(PROC / 'train.csv', index=False)\n",
    "val.to_csv(PROC / 'val.csv', index=False)\n",
    "test.to_csv(PROC / 'test.csv', index=False)\n",
    "\n",
    "\n",
    "print('Data Splitting Complete:')\n",
    "print('Train:', train.shape, '| Val:', val.shape, '| Test:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee77a3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 8. Feature Importance Exploration (Optional)\n",
    "# ========================\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "\n",
    "X = train.drop(['Recommended_Quantity_kg_per_acre','Fertilizer_Type'], axis=1)\n",
    "y = train['Recommended_Quantity_kg_per_acre']\n",
    "\n",
    "\n",
    "rf.fit(X, y)\n",
    "importances = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=importances.values[:15], y=importances.index[:15])\n",
    "plt.title('Top 15 Feature Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cab3113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# 9. Save Preprocessing Artifacts\n",
    "# ========================\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "# Create 'models' folder if it doesn’t exist\n",
    "models_dir = Path('../models')  # use ../ if your notebook is inside 'notebooks'\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save artifacts\n",
    "joblib.dump(scaler, models_dir / 'scaler.pkl')\n",
    "joblib.dump(label_encoders, models_dir / 'label_encoders.pkl')\n",
    "\n",
    "print(f'✅ Preprocessing artifacts saved in: {models_dir.resolve()}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIML Project (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
